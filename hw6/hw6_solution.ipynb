{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "HW6\n",
    "\n",
    "Xiyao Xu\n",
    "\n",
    "07/12/2024\n"
   ],
   "id": "ad988760f1a39f3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step1-3",
   "id": "b968147038a64e2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:51:13.994174Z",
     "start_time": "2024-07-12T17:50:58.693753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Step 1: 数据处理\n",
    "\n",
    "def transform_data(df):\n",
    "    Ys = df['m_label'].values.reshape(-1, 1)\n",
    "    pixel_columns = [col for col in df.columns if col.startswith('r') and 'c' in col]\n",
    "    Xs = df[pixel_columns].values\n",
    "    Xs = Xs.reshape(-1, 20, 20)\n",
    "    Xs = Xs / 255.0\n",
    "    return Xs, Ys\n",
    "\n",
    "\n",
    "def create_label_dicts(labels):\n",
    "    unicode_to_index = {unicode: idx for idx, unicode in enumerate(sorted(set(labels)))}\n",
    "    index_to_unicode = {idx: unicode for unicode, idx in unicode_to_index.items()}\n",
    "    return unicode_to_index, index_to_unicode\n",
    "\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('AGENCY.csv') \n",
    "\n",
    "# 转换数据\n",
    "Xs, Ys = transform_data(df)\n",
    "\n",
    "# 创建标签字典\n",
    "unicode_to_index, index_to_unicode = create_label_dicts(Ys.flatten())\n",
    "\n",
    "# 将Y值转换为索引\n",
    "Ys = np.array([unicode_to_index[y[0]] for y in Ys])\n",
    "\n",
    "print(\"Xs shape:\", Xs.shape)\n",
    "print(\"Ys shape:\", Ys.shape)\n",
    "print(\"Number of unique labels:\", len(unicode_to_index))\n",
    "\n",
    "# Step 2: 模型训练\n",
    "\n",
    "# 将数据转换为PyTorch张量\n",
    "X_tensor = torch.FloatTensor(Xs).unsqueeze(1)  # 添加通道维度\n",
    "y_tensor = torch.LongTensor(Ys)\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class CharacterCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CharacterCNN(num_classes=len(unicode_to_index)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'character_cnn_model.pth')\n",
    "\n",
    "\n",
    "# Step 3: 评估和分析\n",
    "\n",
    "# 1. 使用交叉验证评估模型\n",
    "def cross_validate(X, y, num_folds=5):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = CharacterCNN(num_classes=len(unicode_to_index)).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  # 训练10个epoch\n",
    "            model.train()\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Fold {fold} Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    print(f'Average Accuracy: {sum(accuracies) / len(accuracies):.2f}%')\n",
    "\n",
    "\n",
    "cross_validate(X_tensor, y_tensor)\n",
    "\n",
    "\n",
    "# 2. 分析错误分类的样本\n",
    "def analyze_misclassifications(model, dataloader):\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for i in range(len(batch_y)):\n",
    "                if predicted[i] != batch_y[i]:\n",
    "                    misclassified.append((batch_X[i], batch_y[i], predicted[i]))\n",
    "    return misclassified\n",
    "\n",
    "\n",
    "misclassified = analyze_misclassifications(model, test_loader)\n",
    "\n",
    "# 显示一些错误分类的样本\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (img, true_label, pred_label) in enumerate(misclassified[:9]):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(img.cpu().squeeze(), cmap='gray')\n",
    "    ax.set_title(f'True: {index_to_unicode[true_label.item()]}, Pred: {index_to_unicode[pred_label.item()]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('misclassified_samples.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# 3. 在不同字体上测试模型\n",
    "def test_on_different_font(model, font_file):\n",
    "    df_new = pd.read_csv(font_file)\n",
    "    Xs_new, Ys_new = transform_data(df_new)\n",
    "    X_new_tensor = torch.FloatTensor(Xs_new).unsqueeze(1)\n",
    "    y_new_tensor = torch.LongTensor([unicode_to_index.get(y[0], -1) for y in Ys_new])\n",
    "\n",
    "    new_dataset = TensorDataset(X_new_tensor, y_new_tensor)\n",
    "    new_loader = DataLoader(new_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in new_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on new font: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# 另一个字体文件\n",
    "test_on_different_font(model, 'ARIAL.csv')\n",
    "\n",
    "\n",
    "# 4. 分析模型的不确定性\n",
    "def analyze_uncertainty(model, dataloader):\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            max_probs, _ = torch.max(probabilities, dim=1)\n",
    "            uncertainties.extend(max_probs.cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(uncertainties, bins=50)\n",
    "    plt.title('Distribution of Model Certainty')\n",
    "    plt.xlabel('Max Probability')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('model_uncertainty.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analyze_uncertainty(model, test_loader)\n",
    "\n",
    "print(\"Evaluation and analysis complete!\")"
   ],
   "id": "dddd67857ea41378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs shape: (1004, 20, 20)\n",
      "Ys shape: (1004,)\n",
      "Number of unique labels: 251\n",
      "Epoch [1/10], Test Accuracy: 0.00%\n",
      "Epoch [2/10], Test Accuracy: 0.00%\n",
      "Epoch [3/10], Test Accuracy: 0.00%\n",
      "Epoch [4/10], Test Accuracy: 0.50%\n",
      "Epoch [5/10], Test Accuracy: 1.00%\n",
      "Epoch [6/10], Test Accuracy: 8.46%\n",
      "Epoch [7/10], Test Accuracy: 16.92%\n",
      "Epoch [8/10], Test Accuracy: 24.88%\n",
      "Epoch [9/10], Test Accuracy: 32.34%\n",
      "Epoch [10/10], Test Accuracy: 34.83%\n",
      "Training complete!\n",
      "Fold 1 Accuracy: 39.80%\n",
      "Fold 2 Accuracy: 34.83%\n",
      "Fold 3 Accuracy: 39.80%\n",
      "Fold 4 Accuracy: 46.27%\n",
      "Fold 5 Accuracy: 37.50%\n",
      "Average Accuracy: 39.64%\n",
      "Accuracy on new font: 18.39%\n",
      "Evaluation and analysis complete!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step4",
   "id": "c091b8f518d51ba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:51:27.627782Z",
     "start_time": "2024-07-12T17:51:13.995492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from step123 import X_tensor\n",
    "\n",
    "\n",
    "# 定义自编码器模型\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 添加噪声到图像\n",
    "def add_noise(images, noise_factor=0.5):\n",
    "    noisy_images = images + noise_factor * torch.randn(*images.shape)\n",
    "    return torch.clamp(noisy_images, 0., 1.)\n",
    "\n",
    "\n",
    "# 训练自编码器\n",
    "def train_autoencoder(model, train_loader, num_epochs=50):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            img, _ = data\n",
    "            img = img.to(device)\n",
    "            noisy_img = add_noise(img)\n",
    "\n",
    "            output = model(noisy_img)\n",
    "            loss = criterion(output, img)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# 可视化结果\n",
    "def visualize_denoising(model, test_images):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy_images = add_noise(test_images)\n",
    "        denoised_images = model(noisy_images)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            idx = i * 3 + j\n",
    "            if idx < len(test_images):\n",
    "                axes[i, j].imshow(test_images[idx].squeeze().cpu(), cmap='gray')\n",
    "                axes[i, j].set_title('Original')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('original_images.png')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            idx = i * 3 + j\n",
    "            if idx < len(noisy_images):\n",
    "                axes[i, j].imshow(noisy_images[idx].squeeze().cpu(), cmap='gray')\n",
    "                axes[i, j].set_title('Noisy')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('noisy_images.png')\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            idx = i * 3 + j\n",
    "            if idx < len(denoised_images):\n",
    "                axes[i, j].imshow(denoised_images[idx].squeeze().cpu(), cmap='gray')\n",
    "                axes[i, j].set_title('Denoised')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('denoised_images.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 主要步骤\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 使用之前的 X_tensor\n",
    "autoencoder = DenoisingAutoencoder().to(device)\n",
    "autoencoder_train_loader = DataLoader(TensorDataset(X_tensor, X_tensor), batch_size=32, shuffle=True)\n",
    "\n",
    "# 训练自编码器\n",
    "train_autoencoder(autoencoder, autoencoder_train_loader)\n",
    "\n",
    "# 可视化结果\n",
    "test_images = X_tensor[:9].to(device)  # 选择9张图像进行可视化\n",
    "visualize_denoising(autoencoder, test_images)\n",
    "\n",
    "print(\"Denoising autoencoder training and visualization complete!\")"
   ],
   "id": "1b3418a34c5d31a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1423\n",
      "Epoch [2/50], Loss: 0.0850\n",
      "Epoch [3/50], Loss: 0.0597\n",
      "Epoch [4/50], Loss: 0.0522\n",
      "Epoch [5/50], Loss: 0.0541\n",
      "Epoch [6/50], Loss: 0.0454\n",
      "Epoch [7/50], Loss: 0.0334\n",
      "Epoch [8/50], Loss: 0.0346\n",
      "Epoch [9/50], Loss: 0.0322\n",
      "Epoch [10/50], Loss: 0.0412\n",
      "Epoch [11/50], Loss: 0.0486\n",
      "Epoch [12/50], Loss: 0.0377\n",
      "Epoch [13/50], Loss: 0.0320\n",
      "Epoch [14/50], Loss: 0.0377\n",
      "Epoch [15/50], Loss: 0.0450\n",
      "Epoch [16/50], Loss: 0.0381\n",
      "Epoch [17/50], Loss: 0.0258\n",
      "Epoch [18/50], Loss: 0.0380\n",
      "Epoch [19/50], Loss: 0.0403\n",
      "Epoch [20/50], Loss: 0.0378\n",
      "Epoch [21/50], Loss: 0.0460\n",
      "Epoch [22/50], Loss: 0.0232\n",
      "Epoch [23/50], Loss: 0.0267\n",
      "Epoch [24/50], Loss: 0.0355\n",
      "Epoch [25/50], Loss: 0.0327\n",
      "Epoch [26/50], Loss: 0.0315\n",
      "Epoch [27/50], Loss: 0.0334\n",
      "Epoch [28/50], Loss: 0.0312\n",
      "Epoch [29/50], Loss: 0.0348\n",
      "Epoch [30/50], Loss: 0.0326\n",
      "Epoch [31/50], Loss: 0.0317\n",
      "Epoch [32/50], Loss: 0.0443\n",
      "Epoch [33/50], Loss: 0.0363\n",
      "Epoch [34/50], Loss: 0.0283\n",
      "Epoch [35/50], Loss: 0.0347\n",
      "Epoch [36/50], Loss: 0.0343\n",
      "Epoch [37/50], Loss: 0.0338\n",
      "Epoch [38/50], Loss: 0.0304\n",
      "Epoch [39/50], Loss: 0.0289\n",
      "Epoch [40/50], Loss: 0.0284\n",
      "Epoch [41/50], Loss: 0.0270\n",
      "Epoch [42/50], Loss: 0.0278\n",
      "Epoch [43/50], Loss: 0.0288\n",
      "Epoch [44/50], Loss: 0.0331\n",
      "Epoch [45/50], Loss: 0.0300\n",
      "Epoch [46/50], Loss: 0.0293\n",
      "Epoch [47/50], Loss: 0.0298\n",
      "Epoch [48/50], Loss: 0.0242\n",
      "Epoch [49/50], Loss: 0.0361\n",
      "Epoch [50/50], Loss: 0.0349\n",
      "Denoising autoencoder training and visualization complete!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparison of training on multiple fonts",
   "id": "ce29737a8d034dc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:51:41.511458Z",
     "start_time": "2024-07-12T17:51:27.628421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 定义 CharacterCNN 类\n",
    "class CharacterCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def transform_data(df):\n",
    "    Ys = df['m_label'].values.reshape(-1, 1)\n",
    "    pixel_columns = [col for col in df.columns if col.startswith('r') and 'c' in col]\n",
    "    Xs = df[pixel_columns].values\n",
    "    Xs = Xs.reshape(-1, 20, 20)\n",
    "    Xs = Xs / 255.0\n",
    "    return Xs, Ys\n",
    "\n",
    "\n",
    "def create_label_dicts(labels):\n",
    "    unicode_to_index = {unicode: idx for idx, unicode in enumerate(sorted(set(labels)))}\n",
    "    index_to_unicode = {idx: unicode for unicode, idx in unicode_to_index.items()}\n",
    "    return unicode_to_index, index_to_unicode\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path, unicode_to_index=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    Xs, Ys = transform_data(df)\n",
    "    if unicode_to_index is None:\n",
    "        unicode_to_index, _ = create_label_dicts(Ys.flatten())\n",
    "    X_tensor = torch.FloatTensor(Xs).unsqueeze(1)\n",
    "    y_tensor = torch.LongTensor([unicode_to_index.get(y[0], -1) for y in Ys])\n",
    "    return X_tensor, y_tensor, unicode_to_index\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, num_epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载所有数据以创建完整的unicode_to_index字典\n",
    "df_agency = pd.read_csv('AGENCY.csv')\n",
    "df_baiti = pd.read_csv('BAITI.csv')\n",
    "df_arial = pd.read_csv('ARIAL.csv')\n",
    "\n",
    "all_labels = np.concatenate([df_agency['m_label'].values, df_baiti['m_label'].values, df_arial['m_label'].values])\n",
    "unicode_to_index, _ = create_label_dicts(all_labels)\n",
    "\n",
    "# 现在使用这个完整的字典加载数据\n",
    "X_agency, y_agency, _ = load_and_preprocess_data('AGENCY.csv', unicode_to_index)\n",
    "X_baiti, y_baiti, _ = load_and_preprocess_data('BAITI.csv', unicode_to_index)\n",
    "X_arial, y_arial, _ = load_and_preprocess_data('ARIAL.csv', unicode_to_index)\n",
    "\n",
    "# 单字体训练（AGENCY）\n",
    "X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_agency, y_agency, test_size=0.2,\n",
    "                                                                                random_state=42)\n",
    "train_loader_single = DataLoader(TensorDataset(X_train_single, y_train_single), batch_size=32, shuffle=True)\n",
    "test_loader_single = DataLoader(TensorDataset(X_test_single, y_test_single), batch_size=32, shuffle=False)\n",
    "\n",
    "model_single = CharacterCNN(num_classes=len(unicode_to_index)).to(device)\n",
    "print(\"Training single font model (AGENCY)...\")\n",
    "accuracy_single = train_and_evaluate(model_single, train_loader_single, test_loader_single)\n",
    "\n",
    "# 多字体训练（AGENCY + BAITI）\n",
    "X_multi = torch.cat((X_agency, X_baiti), 0)\n",
    "y_multi = torch.cat((y_agency, y_baiti), 0)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2,\n",
    "                                                                            random_state=42)\n",
    "train_loader_multi = DataLoader(TensorDataset(X_train_multi, y_train_multi), batch_size=32, shuffle=True)\n",
    "test_loader_multi = DataLoader(TensorDataset(X_test_multi, y_test_multi), batch_size=32, shuffle=False)\n",
    "\n",
    "model_multi = CharacterCNN(num_classes=len(unicode_to_index)).to(device)\n",
    "print(\"Training multi-font model (AGENCY + BAITI)...\")\n",
    "accuracy_multi = train_and_evaluate(model_multi, train_loader_multi, test_loader_multi)\n",
    "\n",
    "# 在未见过的字体上测试（ARIAL）\n",
    "test_loader_unseen = DataLoader(TensorDataset(X_arial, y_arial), batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Testing on unseen font (ARIAL)...\")\n",
    "accuracy_unseen_single = train_and_evaluate(model_single, train_loader_single, test_loader_unseen, num_epochs=0)\n",
    "accuracy_unseen_multi = train_and_evaluate(model_multi, train_loader_multi, test_loader_unseen, num_epochs=0)\n",
    "\n",
    "print(f\"Single font (AGENCY) accuracy: {accuracy_single:.2f}%\")\n",
    "print(f\"Multi font (AGENCY + BAITI) accuracy: {accuracy_multi:.2f}%\")\n",
    "print(f\"Unseen font (ARIAL) accuracy - Single font model: {accuracy_unseen_single:.2f}%\")\n",
    "print(f\"Unseen font (ARIAL) accuracy - Multi font model: {accuracy_unseen_multi:.2f}%\")"
   ],
   "id": "61de5f2ab5f1d4c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training single font model (AGENCY)...\n",
      "Epoch [2/10]\n",
      "Epoch [4/10]\n",
      "Epoch [6/10]\n",
      "Epoch [8/10]\n",
      "Epoch [10/10]\n",
      "Training multi-font model (AGENCY + BAITI)...\n",
      "Epoch [2/10]\n",
      "Epoch [4/10]\n",
      "Epoch [6/10]\n",
      "Epoch [8/10]\n",
      "Epoch [10/10]\n",
      "Testing on unseen font (ARIAL)...\n",
      "Single font (AGENCY) accuracy: 27.36%\n",
      "Multi font (AGENCY + BAITI) accuracy: 52.35%\n",
      "Unseen font (ARIAL) accuracy - Single font model: 12.05%\n",
      "Unseen font (ARIAL) accuracy - Multi font model: 16.11%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "38819c2b329f49df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Test accuracy on different font sets:\n",
    "The code is tested on the new font (ARIAL.csv) and the accuracy is 13.86%. This result is significantly lower than the test accuracy on the original font (35.32%). This indicates that the model does not generalize well across fonts.\n",
    "\n",
    "2. Effect of multi-font training on accuracy:\n",
    "\n",
    "The accuracy of the single-font (AGENCY) model is 27.86%\n",
    "The accuracy of the multi-font (AGENCY + BAITI) model is 51.60%\n",
    "\n",
    "Conclusion: Multi-font training significantly improves the accuracy of the model, from 27.86% to 51.60%, an increase of nearly 24 percentage points. This shows that increasing the training data of different fonts can significantly improve the overall performance and generalization ability of the model.\n",
    "Compared with single-font training, the performance of the multi-font trained model on unseen fonts:\n",
    "\n",
    "The accuracy of the single-font model on the unseen ARIAL font is 15.16%\n",
    "The accuracy of the multi-font model on the unseen ARIAL font is 19.78%\n",
    "\n",
    "Conclusion: The multi-font trained model performs slightly better than the single-font trained model on the unseen font (ARIAL). The accuracy increased from 15.16% to 19.78%, an increase of about 4.6 percentage points. This shows that multi-font training does improve the model's generalization ability for new fonts, but the improvement is not as significant as the improvement on known fonts.\n",
    "\n",
    "Accuracy on Unseen Fonts:\n",
    "As mentioned above, the multi-font trained model has an accuracy of 19.78% on the ARIAL font. This relatively low accuracy shows that even after multi-font training, the model still faces great challenges on completely unseen fonts.\n",
    "\n",
    "Summary:\n",
    "Multi-font training does improve the overall performance and generalization ability of the model. It has a significant improvement on known fonts and some improvement on unknown fonts. However, the model's performance on completely unseen fonts is still relatively poor, which reflects the complexity of the character recognition task, especially the difficulty in dealing with new fonts. This result emphasizes that in practical applications, more complex model architectures, more diverse training data, or font recognition-specific techniques may be needed to further improve the model's performance on new fonts.\n",
    "\n",
    "3. Misclassification patterns:\n",
    "From misclassified_samples.png, we can observe the following patterns:\n",
    "a. Complex characters are more likely to be misclassified, such as the first and second characters in the first row (Unicode 110 and 103).\n",
    "b. The model seems to have difficulty recognizing some special symbols, such as the second character in the second row (Unicode 8226).\n",
    "c. Some characters with similar shapes are misrecognized, such as the first and third characters in the third row (Unicode 197 and 208).\n",
    "Uncertainty of the model:\n",
    "From model_uncertainty.png, we can observe:\n",
    "a. The distribution of model certainty is quite wide, ranging from about 0.1 to 1.0.\n",
    "b. There is a clear peak around 0.2, indicating that there are quite a few predictions that the model is not very sure about.\n",
    "c. There is also a small peak between 0.9 and 1.0, indicating that the model is very sure about some predictions.\n",
    "Examples of model uncertainty:\n",
    "In misclassified_samples.png, we can find some examples where the model may be uncertain:\n",
    "a. The second character in the second row (true: 8226, predicted: 45): This is a special symbol, and the model may not be sure about the recognition of such characters.\n",
    "b. The second character in the third row (true: 8722, predicted: 45): This is also a special symbol, and the model also predicts 45, which may indicate that the model has systematic uncertainty in the recognition of such symbols.\n",
    "c. The third character in the first row (true: 8729, predicted: 45): This is another example of being misidentified as 45, further confirming the uncertainty of the model on some special characters.\n",
    "\n",
    "Summary:\n",
    "The model shows high error rates and uncertainties on complex characters, special symbols, and characters with similar shapes. The model's certainty distribution shows that a considerable portion of the predictions are uncertain (certainty is less than 0.5), which indicates that the model has difficulty making confident judgments in many cases. To improve the model, you can consider increasing the training samples of these easily confused characters, or designing specific feature extraction methods for special symbols.\n",
    "\n"
   ],
   "id": "800fe430c8af25a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
